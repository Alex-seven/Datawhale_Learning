# 目录
**Task0**
Q1：打开jupyter notebook后偶尔会出现无工具栏
Q2：jupyter notebook 在使用中有什么好用的小技巧吗？
Q3：markdown编辑使用html+css样式本地上可以显示效果，但是上传到github上样式都没有了，这是什么回事呢？
Q4：发现commit message写错了的时候该怎么修改？
Q5： jupyter notebook写python程序的时候，要打开一个文件或者说一张图片，相对路径是怎样的？（貌似不是当前的Python3）我这里直接用了绝对路径

**Task1**
Q1：Jupyter的markdown可以像typora那样用[TOC]一键生成目录吗？
Q2：numpy里有直接对多维数组求相关系数的命令吗? 
Q3：arr = np.array([1, 2, 3, 4, 5])，教材显示arr的类型是dtype('int64')，而jupyter notebook显示结果为dtype('int32')，请问是由于什么原因导致的？
Q4：学习中发现浮点数不能轻易比较，容易出错。eg:0.3==0.3 TRUE  (0.15+0.15 == 0.2+0.1) FALSE
Q5：Numpy下的这么多函数和使用方法需要全部熟记吗？哪些知识点Numpy库核心?有必要掌握诸如生成伪随机数这类知识点吗?还是等用到的时候再去看文档说明呢?个人更倾向于后者.
Q6：max()和argmax()怎么理解？
Q7：在学习第四章时有的数组后面跟着方法，有的直接np后面带着函数输入参数，这两种有什么不同吗？

**Task2**
Q1：pandas有什么好的方法来解决读入好几G文件时内存不足？
Q2：（1）：iloc()和 loc()这两个索引方式一个是左闭右开，一个是左闭右闭，容易混淆。（2）fillna()，fill_value是否是一样
Q3：检测缺失值用isnull(),但对于大量数据时，有什么办法可以方便看出来呢？
Q4：在用传入axis=1按行进行求和运算时，NA值没有自动排除，出来的结果是0.00。没有搞明白是哪出了问题。
Q5：为什么在语句 data.unique() 后print (data)仍是原来的data内容，只有data1=data.unique()后，才可以得到想要的结果。
Q6： dataframe中的axis参数怎么确定在哪个方向上进行操作？
Q7： DataFrame的apply()、applymap()、map()三个方法的区别是什么？分别在什么场合使用？
调用对象不同,

**Task3**
Q1：有其他的库能更快捷更高效访问所存的数据吗？ 
Q2：为什么cat a.xlsx文件会乱码，是不是csv和xlsx的编码方式不同造成的？是否需要先转化编码格式？ 
Q3：pandas读取文件时怎么使用正则表达式来指定分隔符?
Q4： data[0]['title'] ['title']有哪些区别。[0]是指的一个表还是什么意思？

**Task4**
Q1：_ = df.fillna(0, inplace=True)中的_是什么用法？
Q2：请问哑变量在实际数据分析中在什么情况下会运用到呢？
Q3：1. df.any()选项中，如axis=1，是否对应的行只有在所有的值都不满足要求时才返回False？2. 如果数据集的某个列有多个分类，除了pandas.get_dummies函数之外，有没有其他的方法可以实现类似的编码？
Q4： "dropna()中的thresh到底是什么用？
Q5： lower = data['food'].str.lower() 原理是什么，是要字母排序？

**Task5**
Q1： pivot方法可否看做excel的数据透视表操作？若不能两者有什么区别？
Q2： 数据合并要是两个表数据量都很大的话，内存不够怎么办？
Q3： join 和 merge的区别是什么？
Q4： 对于大型的数据 pandas的数据合并和层次话索引还可以很好操作吗？感觉一两个标签就已经很晕了

**Task6**
Q1： 第一节，df.groupby('key1').mean()为什么key2没有被识别为数据呢？如果不是mean()而是别的函数就会是被识别为要group的数据呢？
Q2： df.groupby(['key1','key2'] [['data2']].mean()和s_grouped = df.groupby(['key1','key2'] ['data2'];s_grouped.mean()的区别，为何后者传入的是单个列名。
Q3： 一般对缺失值填充主要用什么方式来确定要填充均值或者中值或者其他方式呢？？毕竟不合理的填充会引起更大的噪声
Q4： get_suit = lambda card: card[-1] 这个lambda是怎么使用呢?
Q5：GroupBy中agg()函数和apply()函数的区别

**Task7**
Q1：想了解下pandas库迭代的业务需求都是哪些方面的?换句话说，如果pandas是数据分析的利器，那么作为数据分析的从业者想了解工作相关的前沿信息有什么好的渠道或者平台推荐吗？
Q2：除GroupBy函数外，还有哪些分类函数，相比起来优缺点有什么？
Q3："f(df)和df.pipe(f)是等价的，为什么说pipe使得链式声明更容易? pipe的原理或本质是什么？"
Q4：无序分类实例也会有[foo < bar < baz]。通过整数输出形式也会有排序，那么无序体现在哪？

**Task8**
Q1：画图注释的annotate函数参数不是很理解；seaborn做barplot的例子出图有问题？
Q2："1. 在章节9.1.5中，用含title和xlabel作为键的字典向ax.set()传入参数，可以批量设置绘图选项，那么，如何批量设置如何批量设置xticks, xticklabels, xlabels等等参数呢？
2. 在章节9.1.7中，crisis_data是列表类型的数据，for循环中，为什么能辨别date和label呢？如果把其中一个去掉就不行了，这又是为什么呢？

**Task9**
Q1：1.三种移动窗口函数的区别2.锚点偏移量（MonthEnd）的日期是如何确定？
Q2：三种移动窗口函数在实际应用场景有哪些？哪种应用频率最高？
Q3：1.企业级使用三种移动窗口函数哪一种比较频繁

# Task0：Jupyter notebook + Github 环境搭建及使用
**Q1：打开jupyter notebook后偶尔会出现无工具栏**
刷新界面

**Q2：jupyter notebook 在使用中有什么好用的小技巧吗？**
Magic指令，参照书《Python for Data Analysis》2nd中2.2 IPython BasicsAPPENDIX BMore on the IPython System

**Q3：markdown编辑使用html+css样式本地上可以显示效果，但是上传到github上样式都没有了，这是什么回事呢？**
github不提供html,css渲染和latex解析，请自行在浏览器安装插件

**Q4：发现commit message写错了的时候该怎么修改？**
git commit -m "new_message"覆盖你提交的message

**Q5： jupyter notebook写python程序的时候，要打开一个文件或者说一张图片，相对路径是怎样的？（貌似不是当前的Python3）我这里直接用了绝对路径**
相对地址：相对你notebook所在的地址，请先明确notebook在你系统的位置。
相对路径是相对于当前文件位置
而绝对路径是相对于系统根目录的位置
一般编程都用相对位置，但实际上最终都转换为绝对路径，例如web网站内部网页的跳转

# Task1：Python 基础 + Numpy 基础
**Q1：Jupyter的markdown可以像typora那样用[TOC]一键生成目录吗？**
1. 安装jupyter扩展包

pip install jupyter_contrib_nbextensions
1. 配置jupyter用户设置

注意：**关闭jupyter notebook**
jupyter contrib nbextension install --user --skip-running-check
1. 设置目录

![图片](https://uploader.shimo.im/f/qRPviIaJZHI54m6R.png!thumbnail)
1. [TOC]生成目录

![图片](https://uploader.shimo.im/f/saz948bsiaYkm84C.png!thumbnail)

**Q2：numpy里有直接对多维数组求相关系数的命令吗? **
问题描述不明，求两个数组间的相关系数还是数组里每列的相关系数。
描述下相关函数吧
np.var()求方差$\sigma^2$，标准差$\sigma$开平方根即可($\sqrt{np.var()}$)
np.cov()求协方差
np.correlate()求相关系数

**Q3：arr = np.array([1, 2, 3, 4, 5])，教材显示arr的类型是dtype('int64')，而jupyter notebook显示结果为dtype('int32')，请问是由于什么原因导致的？**
版本变迁……
我认为主要原因还是考虑数组所占空间的大小，改为了4个字节，毕竟c/c++，java int默认也是4个字节。

**Q4：学习中发现浮点数不能轻易比较，容易出错。eg:0.3==0.3 TRUE  (0.15+0.15 == 0.2+0.1) FALSE**
见numpy-100 练习48
np.finfo(dtype).eps
np.float32的最小增量为1.1920929e-07
np.float64的最小增量为2.220446049250313e-16
由此可见浮点数在计算机内存表示其实是不精确的，有最小增量，所以一般比较会加一个范围值，例如$e^{-5}$。
为什么浮点数表示不精确？
最直观的解释是数据在计算机内部以0，1表示，位数有限，而浮点数是无限的。用有限的数编码无限的数，肯定不能全部概括，且存在最大值，最小值和最小增量。
关于浮点数在计算机表示的理论和规范，大家可以看下**IEEE754**。

**Q5：Numpy下的这么多函数和使用方法需要全部熟记吗？哪些知识点Numpy库核心?有必要掌握诸如生成伪随机数这类知识点吗?还是等用到的时候再去看文档说明呢?个人更倾向于后者.**
将书上的代码先理解，理解numpy的核心思想及功能，其余的知识点等到你有需要时再去查询相关文档、博客和论坛。

**Q6：max()和argmax()怎么理解？**
max()求数组中的最大值
argmax()求数组中的最大值的索引值

**Q7：在学习第四章时有的数组后面跟着方法，有的直接np后面带着函数输入参数，这两种有什么不同吗？**
np.ufunc是类方法(class method)
arr.ufunc是实例方法(instance method)
类方法比实例方法多了个参数:arr，但其余参数都一致，本质上都执行相同功能
因为python是解释性语言，而在jupyer默认没有载入JIT(动态即时编译)，因此不知道对象的类型，没有编码提示。
查询函数说明，可以查看文档
需要更好的编码提示，可以在IDE(例如Pycharm)编码。
**有序dict**
跟索引底层的实现机制有关
dict或者hash set本身是无序的，而在python3.6版本及以后使用类似OrderedDict结构维护了输入时的顺序。

# Task2：Pandas 基础
**Q1：pandas有什么好的方法来解决读入好几G文件时内存不足？**
分多次将磁盘上的文件读入内存中(**分块读取**)，以便接下来的数据处理工作。
读取文件时指定参数**chunksize**的大小，以及设置**iterator**=True
```
import pandas as pd
path = 'datasets/titanic/train.csv'

reader = pd.read_csv(path, chunksize=100, iterator=True)  # return TextParser
print(type(reader))  # TextParser

# # 单次获取
# chunk = reader.get_chunk(size=100)
# print(chunk.head(5))

# 迭代获取
for chunk in reader:
    # deal data by chunk
    print(chunk.head(5))
    
```

**Q2：（1）：iloc()和 loc()这两个索引方式一个是左闭右开，一个是左闭右闭，容易混淆。（2）fillna()，fill_value是否是一样**
(1)iloc使用数字索引，跟range()中start, end, step的用法一致:[ )
loc使用标签索引，因为是标签且标签不一定按顺序排列，所以包含两个区间顶点值:[ ]
注：数字也是标签，所以loc也可以按数字索引，但是不建议混合使用。
(2)
提问中应为**fill_value**，而不是fill_values
fill_value为参数，fillna为ufunc（函数），其作用都是填充NA值

**Q3：检测缺失值用isnull(),但对于大量数据时，有什么办法可以方便看出来呢？**
`df.info()`描述基本统计信息

**Q4：在用传入axis=1按行进行求和运算时，NA值没有自动排除，出来的结果是0.00。没有搞明白是哪出了问题。**
在我运行的代码中，NAN不参与运算，或者当作0
```
import numpy as np
import pandas as pd
df = pd.DataFrame([1, 2, np.NAN])  # 3.0
print(df.sum())

df = pd.DataFrame([np.NAN])  # 0.0
print(df.sum())
```

**Q5：为什么在语句 data.unique() 后print (data)仍是原来的data内容，只有data1=data.unique()后，才可以得到想要的结果。**
data.unique()并**不在**原数组上直接操作，而是将操作的结果**返回**，所以需要**赋值**才能保留操作的结果。

**Q6： dataframe中的axis参数怎么确定在哪个方向上进行操作？**
默认**aixs=0**（沿行方向）
axis的设置同**NumPy**中**ndarray**一致，可返回第四章再详细看看，以下给出简单的示意图。
![图片](https://uploader.shimo.im/f/B9FLYHbrDQoCYa9h.png!thumbnail)

**Q7： DataFrame的apply()、applymap()、map()三个方法的区别是什么？分别在什么场合使用？**
**调用对象不同**,
**df**.apply()和**df**.applymap()
**series**.map()
**作用都是映射数组**，apply(axis=1)等价于applymap()
所以根据方便和你的编程习惯使用它们就好啦！

# Task3：数据加载，存储和文件格式
**Q1：有其他的库能更快捷更高效访问所存的数据吗？ **
一般来说pandas封装的函数能帮助更快捷更高效的处理所存二维数据，若数据结构更为复杂，使用**数据库**和**SQL语句**更为高效、便捷。

**Q2：为什么cat a.xlsx文件会乱码，是不是csv和xlsx的编码方式不同造成的？是否需要先转化编码格式？** 
cat指令只能有效读取文本文件，而xlsx是Microsoft自定义的一种格式，准备来说是**文件编码**方式**不同**，而不是我们通常说的**字符编码**格式(字符编码跟你的系统和软件编码设置有关)。

**Q3：pandas读取文件时怎么使用正则表达式来指定分隔符?**
pd.read_csv()等读取文件函数有两个参数**sep**和**delimiter**
**sep** : str, default ‘,’
指定分隔符，可以为**正则表达式**，例如'\r\t'。
delimiter : str, default None
定界符，备选分隔符（如果指定该参数，则sep参数失效）
若需要对字符串做更复杂的操作，需要使用更基本的库。
**关于分隔符处理**
* csv module只能处理单个分隔符；
* 需处理多个分隔符，使用string.split
* 更复杂的操作使用正则表达式:re.split

**Q4： data[0]['title'] ['title']有哪些区别。[0]是指的一个表还是什么意思？**
data是一个列表，data[0]是一个字典，columns指定构建DataFrame的列。
其实很好理解，因为之前有用**list of dict**创建DataFrame，现在只不过**指定了列**(columns)

# Task4：数据清洗和准备
**Q1：_ = df.fillna(0, inplace=True)中的_是什么用法？**
_是**变量名**，用来表示这个变量**无实际含义**，作用等价于**临时变量**。

**Q2：请问哑变量在实际数据分析中在什么情况下会运用到呢？**
哑变量就是**保存**自定义生成的数据，存储这些信息有利于我们进一步利用数据。
例如在学生成绩管理系统中，输入只有每个的学生成绩，我们可以计算他们的平均成绩，求每个人的绩点，以待评奖评奖时参考。

**Q3：1. df.any()选项中，如axis=1，是否对应的行只有在所有的值都不满足要求时才返回False？2. 如果数据集的某个列有多个分类，除了pandas.get_dummies函数之外，有没有其他的方法可以实现类似的编码？**
1. **Pandas**中df.any(axis=1)与**NumPy**arr.any(axis=1)用法一致，含义皆为每行是否**存在**True
all()则判断是否**全**为True
2. **sklearn**中针对不同的对象(Integer, String)，采用不用的编码器实现**one-hot编码**
e.g.OneHotEncoe.g, LabelEncoder, LabelBinarizer, MultiLabelBinarizer
pandas.get_dummies()直接实现**one-hot编码**，无需考虑对象类型，但使用时需注意**sklearn**中tranform()的兼容性。

**Q4： "dropna()中的thresh到底是什么用？**
parameter:thresh,保留**非NA**数据**达到**thresh个的行

![图片](https://uploader.shimo.im/f/3XFYsFaS4LETeirh.png!thumbnail)

**Q5： lower = data['food'].str.lower() 原理是什么，是要字母排序？**
lower = data['food'].str.lower()将'food'字符串全转为**小写字母**
![图片](https://uploader.shimo.im/f/ObUUG5ipX4s8TUdT.png!thumbnail)

# Task5：数据争吵：组合，连接和重新排列
**Q1： pivot方法可否看做excel的数据透视表操作？若不能两者有什么区别？**
excel的数据透视表功能很强大，pd.pivot()只实现了一个功能——将两列数据变为二维表格。

**Q2： 数据合并要是两个表数据量都很大的话，内存不够怎么办？**
数据合并是在数据分析处理最消耗空间和时间的操作。
因此为减少消耗，在数据合并前分别对两个表格进行**条件和属性选择**，减少单个表格的数据。

**Q3： join 和 merge的区别是什么？**
pd.merge(df1, df2) 
df1.join(df2)
二者都执行**连接**操作，本质**等价**。
merge()比join()多了df的索引控制，而这个可以通过删除列/增加列的方式实现等效。

**Q4： 对于大型的数据 pandas的数据合并和层次话索引还可以很好操作吗？感觉一两个标签就已经很晕了**
Pandas基于NumPy实现，便捷高效。
数据分析可没有一把**梭哈**的方法，你预先得规划数据处理过程，再进行编码。即**思维运算->Python实现**

# Task6：数据聚合与分组
**Q1： 第一节，df.groupby('key1').mean()为什么key2没有被识别为数据呢？如果不是mean()而是别的函数就会是被识别为要group的数据呢？**
其实**key2**也按key1的值**分组**
* 但由于df.groupby('key1').mean()做均值计算，因为key2是字符串，没有均值的结果，所以不显示。
* 当你使用group.count()——统计数据个数，即可看到关于**key2的结果**

![图片](https://uploader.shimo.im/f/jJzPWlniHcgS6OjC.png!thumbnail)

**Q2： df.groupby(['key1','key2'] [['data2']].mean()和s_grouped = df.groupby(['key1','key2'] ['data2'];s_grouped.mean()的区别，为何后者传入的是单个列名。**
代码含义求**按key1，key2分组以后data2列的平均值**
s_grouped只是个中间变量，两者写法等价

**Q3： 一般对缺失值填充主要用什么方式来确定要填充均值或者中值或者其他方式呢？？毕竟不合理的填充会引起更大的噪声**
看**个人**对业务或者工程的**理解**，个人觉得用均值的场景多一些
此外数据分析，处理和特征工程是一个**探索**的过程
因此将**数据可视化**对查看数据分布，填充缺失值有一定帮助。

**Q4： get_suit = lambda card: card[-1] 这个lambda是怎么使用呢?**
lambda：匿名函数
card为参数,card[-1]为返回值
这个函数作用是取序列的最后一个值，在书中示例是取字符串的最后一个字符
显示等价形式
```
def get_last(card):
	return card[-1]
```

**Q5：GroupBy中agg()函数和apply()函数的区别**
group.agg(func)和df.apply(func)都接受一个函数作为参数，是group的高级用法
* group.agg(func)：func返回一个值
* group.apply(func)：func返回一个dataframe![图片](https://uploader.shimo.im/f/PHVPfgP1oao5L0KZ.png!thumbnail)![图片](https://uploader.shimo.im/f/x8VA8E3ap18mcLFe.png!thumbnail)
# Task7：Pandas进阶
**Q1：想了解下pandas库迭代的业务需求都是哪些方面的?换句话说，如果pandas是数据分析的利器，那么作为数据分析的从业者想了解工作相关的前沿信息有什么好的渠道或者平台推荐吗？**
pandas用于**数据分析**
1. 考虑自己找数据分析，例如股票行情分析
2. 学习python爬虫，获取数据
3. 看统计数学，掌握分析的相关数学理论
4. 看数据分析有关需求和业务的书籍，例如睿姐在群里发的《精益数据分析》
5. 迈入机器学习，走向kaggle之路

个人浅见，还未就业，望各位大佬指点明路

**Q2：除GroupBy函数外，还有哪些分类函数，相比起来优缺点有什么？**
<a href="https://www.jianshu.com/p/42f1d2909bb6">超好用的 pandas 之 groupby
</a>
Df.groupby()返回**DataFrameGroupBy**对象，方便对每组对象操作
`Categories`分类类型
其他的例如`cut()`和`qcut()`与其说是分类，更准确的说是**统计**。

**Q3："f(df)和df.pipe(f)是等价的，为什么说pipe使得链式声明更容易? pipe的原理或本质是什么？"**
```
#Consider a sequence of function calls:

a = f(df, arg1=v1)
b = g(a, v2, arg3=v3)
c = h(b, arg4=v4)

result = (df.pipe(f, arg1=v1)
          .pipe(g, v2, arg3=v3)
          .pipe(h, arg4=v4))
```
链式调用，编码更便捷，代码更易懂
pipe就是数据管道，返回特定类型，实现代码的一次性处理

**Q4：无序分类实例也会有[foo < bar < baz]。通过整数输出形式也会有排序，那么无序体现在哪？**
![图片](https://uploader.shimo.im/f/5PxPZPuVg2MW0hux.png!thumbnail)
这个问题是在说这个吗？
不是无序排序，而是**指定顺序排序**。不指定顺序，**默认字典顺序排序**。

# Task8：Matplotlib画图及可视化
**Q1：画图注释的annotate函数参数不是很理解；seaborn做barplot的例子出图有问题？**
'''
    xy=(横坐标，纵坐标)  箭头尖端
    xytext=(横坐标，纵坐标) 文字的坐标，指的是最左边的坐标
    arrowprops= {
        facecolor= '颜色',
        shrink = '数字' <1  收缩箭头
    }  箭头格式
'''
**详见**：[Matplotlib 中文用户指南 4.5 标注](https://blog.csdn.net/wizardforcel/article/details/54782628)

**Q2："1. 在章节9.1.5中，用含title和xlabel作为键的字典向ax.set()传入参数，可以批量设置绘图选项，那么，如何批量设置如何批量设置xticks, xticklabels, xlabels等等参数呢？**
```
props = {
    'title': 'My first matplotlib plot2',
    'xlabel': 'Stages2'
}
ax.set(**props)

```
以关键字参数**kwargs的形式批量设置
**2. 在章节9.1.7中，crisis_data是列表类型的数据，for循环中，为什么能辨别date和label呢？如果把其中一个去掉就不行了，这又是为什么呢？**
```
crisis_data = [
    (datetime(2007, 10, 11), 'Peak of bull market'),
    (datetime(2008, 3, 12), 'Bear Stearns Fails'),
    (datetime(2008, 9, 15), 'Lehman Bankruptcy')
]

for date, label in crisis_data:
    pass
```
因为列表中的元素为元组，`for date, label in crisis_data`，通过**拆包**一一对应。
# Task9：时间序列处理
以前做数学建模的时候，会用**AR/MA/ARMA/ARIMA**模型分析时间序列数据。
滑动（移动）窗口(Moving Window Functions)，让我联想到了计算机网络的发送接收文件的滑动窗口以及计算机视觉里的卷积操作。
**滑动(移动)窗口**：为了提升数据的准确性，**用一段区间来表示某个点的取值**，其中这个区间称为窗口。直观解释：**平滑数据**，消除噪音
想要了解滑动窗口更多知识
**详见**：<a href="http://liao.cpython.org/pandas40/">Pandas的时间序列-滑动窗口</a>>

**Q1：1.三种移动窗口函数的区别2.锚点偏移量（MonthEnd）的日期是如何确定？**
1. `close_px.AAPL.rolling(250).mean().plot()` **平均加权**
2. `ma60 = aapl_px.rolling(30, min_periods=20).mean()`
`ewma60 = aapl_px.ewm(span=30).mean()` **指数加权**
3. `score_at_2percent = lambda x: percentileofscore(x, 0.02)`
`result = returns.AAPL.rolling(250).apply(score_at_2percent)`**自定义加权**
移动窗口的区别在于**求权的方式**以及**窗口的大小**不同。
```
from pandas.tseries.offsets import Day, MonthEnd
now = datetime(2019, 7, 27)
now + MonthEnd(2)
```
根据你的数据分析需求设定`MonthEnd`偏移量

**Q2：三种移动窗口函数在实际应用场景有哪些？哪种应用频率最高？**
* 指数移动窗口函数：整体平滑
* 二进制移动窗口函数：增量变化
* 自定义窗口函数：根据分析需求
看《统计数字会撒谎》、《精益数据分析》等书对统计有更多地了解。


**Q3：1.企业级使用三种移动窗口函数哪一种比较频繁**
一般使用**指数移动窗口函数**和**二进制移动窗口函数**。
遇到较为复杂的现实场景，肯定使用**自定义窗口函数**。


# 

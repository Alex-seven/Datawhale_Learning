
【Task1精选问题】
* Q1：使用urllib和request爬虫的区别是？以及两者效率上有差别吗？
* Q2：urllib和reques两个包哪个更常用？怎么确定哪种网页的爬取要用哪种方法更好呢？
* Q3：为什么存成csv格式的时候，中文字符会变成乱码，打开文件时已经用了utf-8编码了？
* Q4：在pycharm 中requests安装不成功怎么回事，  
    
    Could not find a version that satisfies the requirement requests (from versions: )
No matching distribution found for requests？
* Q5：1、post和get按道理获取数据是一样的，只是数据大小有不同，但为什么这里用post获取只能获取第一页数据？为什么函数要写在前门，不能像JAVA一样，写在任何一个地方吗？

【Task2 精选问题】
* Q1：如何翻页获取数据，beautifulsoup中.text和get_text()的区别是什么？
* Q2：如何处理抓取内容的回车和空格？
* Q3：多页内容如何抓取？
* Q4：这两个解析库，大概思想感觉是一样的，就是使用方法不太一样，我们需要把这些都学会吗?是不是熟悉掌握一种就可以了呢？

【Task3 精选问题】
* Q1: rank()排序的规则该怎么理解？mad()函数是从中位数还是均值计算的平均绝对离差？
* Q2: 想问如果爬取多个网页验证码类型不同怎么办，图片类型的，滑动的，还有点击?
* Q3: 构建好代理池后，如果在一次爬虫中自动切换代理？ 比如代理无效，或者代理ip被封，这时自动切换下一个ip。
* Q4: 如何快速的获得网页中元素的属性？

【Task4 精选问题】
* Q1:登录遇到验证码如何解决？类似微博这样的网站有反爬机制，如何解决呢？
* Q2:验证码会随机更换类型，可以通过代码判断是那种类型吗？
* Q3:图形验证码应该如何解决?
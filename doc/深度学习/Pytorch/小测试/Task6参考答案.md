## Task6：
Q1: 优化器对于不同的场景选择上有没有要求？或者说在使用时必须把这几个进行对比？然后取出最优？

A1: 这个优化器其实只要数据和训练的轮数足够效果是差不多的，不同优化器主要的差别就是收敛速度的不同。

Q2: 通常来说优化器的参数很重要，那么我们通过什么样的方法可以确定最优参数呢？

A2: 调参。

Q3: 一定是Adam优化器最好用吗？或者说有没有SGD优化强于Adam的情况？

A3: 一般来说Adam更稳定，可以看吴恩达关于优化器的部分的讲解

https://mooc.study.163.com/learn/2001281003?tid=2001391036&_trace_c_p_k2_=7f8ddb27ae2449af854a44c050993fbf#/learn/content?type=detail&id=2001701052

Q4: 随机梯度下降的特点是什么？怎么实现?

A4: 主要是在theta的更新上，随机梯度下降在更新theta时只是随机选择所有样本中的一个或一个批次，然后对theta求导，所以随机梯度下降具有较快的速度，但是可能陷入局部最优解

Q5: Adam和RMSprop是否适用于大部分神经网络的训练？

A5: 是的